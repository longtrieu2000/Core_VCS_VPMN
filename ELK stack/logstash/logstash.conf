input {
 # kafka {
 #   bootstrap_servers => "10.208.137.83:9092"
 #   topics => ["user_activity"]
 #   codec => json
 # }
  beats {
    host => "0.0.0.0"
    port => "5044"
  }
}

#filter các trường type = filebeat
filter {
  if [type] == "filebeat" {
    grok {
      match => {
        "message" => [
          "%{IPORHOST:client_ip} - %{DATA:ident} %{DATA:auth} \\[%{HTTPDATE:timestamp}\\] \"%{WORD:method} %{DATA:request} HTTP/%{NUMBER:http_version}\" %{NUMBER:status} %{NUMBER:bytes} \"%{DATA:referrer}\" \"%{DATA:agent}\""
        ]
      }
    }

    date {
      match => ["timestamp", "dd/MMM/yyyy:HH:mm:ss Z"]
      target => "@timestamp"
    }

    geoip {
      source => "client_ip"
    }

    mutate {
      add_tag => ["nginx_access"]
    }
  }
}

#filter các log từ file
filter {
  if [path] == "/postgres/logs/mysafe_postgres.log" {
    mutate {
      add_tag => ["postgres_log"]
    }
    grok {
      match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:log_level}:  %{GREEDYDATA:log_message}" }
    }
  }
}

#filter các trường event = domain_block
filter{
  json {
    source => "message"
  }

  mutate {
    remove_field => ["message", "agent", "headers", "tags", "input", "ecs"]
  }

  if [event] != "domain_block" {
    drop {}
  }

  ruby {
    code => '
      event.set("time_bucket", event.get("@timestamp").to_i / 300)
    '
  }

  fingerprint {
    method => "SHA1"
    source => ["[data][domain]", "[data][mac]", "time_bucket"]
    concatenate_sources => true
    target => "[@metadata][docid]"
  }
}

output {
  elasticsearch {
    hosts => ["10.208.137.83:9200"]   #server elasticsearch
    index => "logstash-%{+yyyy.MM.dd}"
    codec => json
    document_id => "%{[@metadata][docid]}"
  }

  stdout {}
}
